Algoritmo que se va a usar: Deep Q-Learning (DQN)

Estados: no usar toda la grilla como entrada, sino features diseñadas a mano:
Altura máxima de la pila.
Número de huecos (espacios vacíos debajo de bloques).
Número de líneas completas.
Variación de altura entre columnas ("bumpiness").
Acciones: elegir la rotación y posición de la pieza actual.
Algoritmo: DQN con una red neuronal pequeña (unas 2-3 capas densas).
Ventajas:
- Mucho más rápido de entrenar.
- No necesitas GPUs grandes.
- Más fácil de debuggear porque puedes ver si el agente aprende reglas simples (ej: evitar huecos).

